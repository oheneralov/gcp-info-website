<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Info Page</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
</head>

<body class="bg-light">
  <div class="container mt-5">
  <h2>Setting up and deploying two simple microservices in Express.js using Jenkins, Traefik, Kubernetes, and Google Cloud Platform</h2>
  <p>Setting up and deploying two simple microservices in Express.js using Jenkins, Traefik, Kubernetes, and Google
    Cloud Platform (GCP) with a load balancer is a complex process that involves multiple steps. Below is a tutorial
    that walks through the process, from coding the microservices to deploying them on GCP using Kubernetes.</p>
  <h2>Prerequisites:</h2>
  <ul>
    <li>Basic knowledge of Node.js, Express.js, and Docker.</li>
    <li>An active Google Cloud account with billing enabled.</li>
    <li>kubectl, gcloud CLI, and Docker installed.</li>
    <li>A Jenkins instance (either local or hosted). Install from official web site and install jdk 21.</li>
    <li>Traefik configured as an ingress controller for Kubernetes.</li>
  </ul>
  <hr>
  <h2>1. Create Two Simple Express.js Microservices</h2>
  <p>We will start by building two simple Express.js microservices (service1 and service2).</p>
  <h3>Microservice 1 (service1)</h3>
  <p>Create a directory for service1 and initialize the project.</p>
  <pre><code>mkdir service1
cd service1
npm init -y</code></pre>
  <p>Install Express.js.</p>
  <pre><code>npm install express</code></pre>
  <p>Create the index.js for the service:</p>
  <pre><code>const express = require('express');
const app = express();
const port = 3000;

app.get('/', (req, res) => {
res.send('Hello from Service 1!');
});

app.listen(port, () => {
console.log(`Service 1 is running on port ${port}`);
});</code></pre>
  <h3>Microservice 2 (service2)</h3>
  <p>Repeat the same steps for service2.</p>
  <pre><code>mkdir ../service2
cd ../service2
npm init -y
npm install express</code></pre>
  <p>Create the index.js for service2:</p>
  <pre><code>const express = require('express');
const app = express();
const port = 3000;

app.get('/', (req, res) => {
res.send('Hello from Service 2!');
});

app.listen(port, () => {
console.log(`Service 2 is running on port ${port}`);
});</code></pre>
  <h2>2. Dockerize the Microservices</h2>
  <p>For deployment on Kubernetes, we need to create Docker images for both services.</p>
  <h3>Create Dockerfile for each service</h3>
  <p>In both the service1 and service2 directories, create a Dockerfile with the following contents:</p>
  <pre><code># Dockerfile
FROM node:14-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 3000
CMD ["node", "index.js"]</code></pre>
  <h3>Build and Push Docker Images</h3>
  <p>Use Docker to build and push the images to a container registry like Google Container Registry (GCR).</p>
  <ol>
    <li>Authenticate with Google Cloud:</li>
    <pre><code>gcloud auth configure-docker</code></pre>
    <li>Build and push images:</li>
    <pre><code># In service1 directory
docker build -t gcr.io/clever-spirit-417020/service1:latest .
docker push gcr.io/clever-spirit-417020/service1:latest
# In service2 directory
docker build -t gcr.io/clever-spirit-417020/service2:latest .
docker push gcr.io/clever-spirit-417020/service2:latest</code></pre>
  </ol>
  <h2>3. Kubernetes Setup on GCP</h2>
  <h3>3.1 Create a Kubernetes Cluster on GCP</h3>
  <ol>
    <li>Create a Kubernetes cluster using Google Kubernetes Engine (GKE):</li>
    <pre><code>gcloud container clusters create microservices-cluster --zone &lt;your-zone&gt;</code></pre>
    <li>Configure kubectl to connect to your cluster:</li>
    <pre><code>gcloud container clusters get-credentials microservices-cluster --zone &lt;your-zone&gt;</code></pre>
  </ol>
  <h3>3.2 Create Kubernetes Deployment and Service Manifests</h3>
  <p>Create a directory k8s-manifests/ where we will store the Kubernetes manifests.</p>
  <h4>Deployment for service1:</h4>
  <pre><code># k8s-manifests/service1-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
name: service1
spec:
replicas: 2
selector:
  matchLabels:
    app: service1
template:
  metadata:
    labels:
      app: service1
  spec:
    containers:
    - name: service1
      image: gcr.io/&lt;your-project-id&gt;/service1:latest
      ports:
      - containerPort: 3000</code></pre>
  <h4>Deployment for service2:</h4>
  <pre><code># k8s-manifests/service2-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
name: service2
spec:
replicas: 2
selector:
  matchLabels:
    app: service2
template:
  metadata:
    labels:
      app: service2
  spec:
    containers:
    - name: service2
      image: gcr.io/&lt;your-project-id&gt;/service2:latest
      ports:
      - containerPort: 3000</code></pre>
  <h4>Services for both:</h4>
  <pre><code># k8s-manifests/service1-service.yaml
apiVersion: v1
kind: Service
metadata:
name: service1
spec:
type: ClusterIP
selector:
  app: service1
ports:
- protocol: TCP
  port: 80
  targetPort: 3000</code></pre>
  <pre><code># k8s-manifests/service2-service.yaml
apiVersion: v1
kind: Service
metadata:
name: service2
spec:
type: ClusterIP
selector:
  app: service2
ports:
- protocol: TCP
  port: 80
  targetPort: 3000</code></pre>
  <h3>3.3 Deploy to Kubernetes</h3>
  <p>Apply the deployments and services to your Kubernetes cluster:</p>
  <pre><code>kubectl apply -f k8s-manifests/service1-deployment.yaml
kubectl apply -f k8s-manifests/service1-service.yaml

kubectl apply -f k8s-manifests/service2-deployment.yaml
kubectl apply -f k8s-manifests/service2-service.yaml</code></pre>
  <h3>3.4 Traefik Ingress Setup</h3>
  <h4>Install Traefik as the Ingress Controller</h4>
  <ol>
    <li>Add Traefik Helm repo:</li>
    <pre><code>scoop install helm
helm repo add traefik https://helm.traefik.io/traefik
helm repo update</code></pre>
    <li>Install Traefik:</li>
    <pre><code>helm install traefik traefik/traefik --set service.type=LoadBalancer</code></pre>
  </ol>
  <h4>Create an Ingress Resource</h4>
  <p>Create an ingress.yaml file to expose both services.</p>
  <pre><code># k8s-manifests/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
name: microservices-ingress
annotations:
  traefik.ingress.kubernetes.io/router.entrypoints: web
spec:
rules:
- host: service1.example.com
  http:
    paths:
    - path: /
      pathType: Prefix
      backend:
        service:
          name: service1
          port:
            number: 80
- host: service2.example.com
  http:
    paths:
    - path: /
      pathType: Prefix
      backend:
        service:
          name: service2
          port:
            number: 80</code></pre>
  <p>Or you can use IngressRoute </p>
  <p>
    kubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v3.2/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml
  </p>
  <pre><code>
    ---
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
name: service1-ingress
namespace: default
spec:
entryPoints:
  - web
routes:
  - match: Host(`oleksandrdesign.com`)
    kind: Rule
    services:
      - name: service1
        port: 80

---
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
name: service2-ingress
namespace: default
spec:
entryPoints:
  - web
routes:
  - match: Host(`service2.oleksandrdesign.com`)
    kind: Rule
    services:
      - name: service2
        port: 80

  </code></pre>
  <p>Apply the ingress to the cluster:</p>
  <pre><code>kubectl apply -f k8s-manifests/ingress.yaml</code></pre>
  <h3>3.5 Configure DNS (Optional)</h3>
  <p>You can configure your DNS to point to the external IP of the Traefik load balancer. Obtain the external IP:</p>
  <pre><code>kubectl get svc traefik</code></pre>
  <p>Set up DNS records for service1.example.com and service2.example.com to point to this IP.</p>
  <h2>4. Jenkins CI/CD Pipeline</h2>
  <h3>4.1 Setup Jenkins Pipeline</h3>
  <ol>
    <li>Install Jenkins plugins:</li>
    <ul>
      <li>Kubernetes plugin.</li>
      <li>Docker plugin.</li>
      <li>Pipeline plugin.</li>
      <li>Google Container Registry Auth</li>
    </ul>
    <li>Create a Jenkins pipeline job with the following pipeline script:</li>
  </ol>
  <pre><code>pipeline {
  agent any

  stages {
      stage('Build') {
          steps {
              script {
                  docker.build("gcr.io/&lt;your-project-id&gt;/service1:latest", "./service1")
                  docker.build("gcr.io/&lt;your-project-id&gt;/service2:latest", "./service2")
              }
          }
      }
      stage('Push to GCR') {
          steps {
              script {
                  docker.withRegistry('https://gcr.io', 'gcr:auth') {
                      docker.image("gcr.io/&lt;your-project-id&gt;/service1:latest").push()
                      docker.image("gcr.io/&lt;your-project-id&gt;/service2:latest").push()
                  }
              }
          }
      }
      stage('Deploy to Kubernetes') {
          steps {
              sh 'kubectl apply -f k8s-manifests/service1-deployment.yaml'
              sh 'kubectl apply -f k8s-manifests/service2-deployment.yaml'
          }
      }
  }
}</code></pre>
  <h2>5. Access Your Microservices</h2>
  <p>After deployment, you can access your microservices via the domain names configured for Traefik:</p>
  <ul>
    <li><a href="http://service1.example.com">http://service1.example.com</a></li>
    <li><a href="http://service2.example.com">http://service2.example.com</a></li>
  </ul>
  <h2>6. Load Balancer</h2>
  <p>GCP’s Kubernetes Engine automatically provisions a load balancer for Traefik. This setup provides high
    availability and distributes traffic across the pods of each service.</p>
  <p>To push Docker images to Google Container Registry (GCR) using Jenkins, the setup is quite similar to Artifact
    Registry. You'll still need the Google Cloud SDK plugin, Docker Pipeline plugin, and some other key
    configurations.</p>
  <p>Here's a sample Jenkins Pipeline script for pushing Docker images to GCR:</p>
  <h3>Required Jenkins Plugins</h3>
  <ol>
    <li>Google Cloud SDK Plugin</li>
    <li>Docker Pipeline Plugin</li>
    <li>Credentials Binding Plugin</li>
    <li>Pipeline Plugin</li>
  </ol>
  <h3>Steps to Set Up</h3>
  <ol>
    <li>Service Account Creation and Key:</li>
    <ul>
      <li>In Google Cloud Console, create a service account with the Storage Admin role (for GCR).</li>
      <li>Download the service account key (JSON format) and add it to Jenkins > Manage Jenkins > Manage Credentials
        under Global credentials.</li>
    </ul>
    <li>Pipeline Script:</li>
  </ol>
  <pre><code>pipeline {
  agent any
  environment {
      GOOGLE_APPLICATION_CREDENTIALS = credentials('your-google-credentials-id') // Jenkins ID for your Google Cloud credentials
      PROJECT_ID = 'your-gcp-project-id'
      IMAGE_NAME = 'your-image-name'
      TAG = 'latest'
      REGION = 'gcr.io' // You can also specify regions like us.gcr.io, eu.gcr.io, or asia.gcr.io if needed
  }
  stages {
      stage('Authenticate to Google Cloud') {
          steps {
              sh 'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS'
              sh 'gcloud config set project $PROJECT_ID'
          }
      }
      stage('Build Docker Image') {
          steps {
              script {
                  docker.build("$REGION/$PROJECT_ID/$IMAGE_NAME:$TAG")
              }
          }
      }
      stage('Push Docker Image to GCR') {
          steps {
              script {
                  docker.withRegistry("https://$REGION", 'gcloud') {
                      docker.image("$REGION/$PROJECT_ID/$IMAGE_NAME:$TAG").push()
                  }
              }
          }
      }
  }
}</code></pre>
  <h3>Explanation of the Script</h3>
  <ul>
    <li>Authenticate to Google Cloud: Uses the service account JSON key to authenticate.</li>
    <li>Build Docker Image: Builds the Docker image using the docker.build() method.</li>
    <li>Push Docker Image to GCR: Pushes the built Docker image to GCR using docker.withRegistry().</li>
  </ul>
  <h3>Important Notes</h3>
  <ul>
    <li>Make sure Docker is set up on your Jenkins instance and configured to interact with GCR.</li>
    <li>Replace placeholders like your-google-credentials-id, your-gcp-project-id, your-image-name, and latest with
      your specific information.</li>
  </ul>
  <p>This should allow you to push Docker images to GCR smoothly. Let me know if you have any questions on customizing
    it!</p>
  <h2>To push Docker images to Google Artifact Registry using Jenkins</h2>
  <p>you need to configure Jenkins with a few plugins and credentials for smooth integration with Google Cloud. Here’s
    a guide on the plugins and steps to set it up:</p>
  <h3>Required Plugins</h3>
  <ul>
    <li>Google Cloud SDK Plugin: This lets you interact with Google Cloud services, including Artifact Registry.</li>
    <li>Docker Pipeline Plugin: Provides Docker support in Jenkins Pipeline (specifically, if you’re using declarative
      pipelines to build and push Docker images).</li>
    <li>Credentials Binding Plugin: Facilitates securely binding credentials, like Google service account keys, in
      Jenkins pipelines.</li>
    <li>Pipeline Plugin: If you’re working with scripted or declarative pipelines, this plugin helps to write pipeline
      scripts to automate the Docker build and push process.</li>
    <li>Google OAuth Credentials Plugin (optional): If you’re using OAuth for Google service authentication, this
      plugin will help manage those credentials.</li>
  </ul>
  <h3>Setup Steps</h3>
  <ol>
    <li>Install the Plugins: In Jenkins, go to Manage Jenkins > Manage Plugins. Search for each plugin by name and
      install them.</li>
    <li>Add Google Cloud Service Account Key:</li>
    <ul>
      <li>In Google Cloud Console, create a service account with permissions for Artifact Registry (usually Artifact
        Registry Writer).</li>
      <li>Generate a JSON key for this service account.</li>
      <li>In Jenkins, go to Manage Jenkins > Manage Credentials, and add the JSON key under Global credentials.</li>
    </ul>
    <li>Configure Docker and Google Cloud in the Pipeline: Use the following basic example pipeline script to log in,
      build, and push to Google Artifact Registry:</li>
  </ol>
  <pre><code>pipeline {
  agent any
  environment {
      GOOGLE_APPLICATION_CREDENTIALS = credentials('your-google-credentials-id') // Replace with your Jenkins credentials ID for Google Cloud
      PROJECT_ID = 'your-gcp-project-id'
      REGION = 'your-artifact-registry-region' // e.g., us-central1
      REPOSITORY = 'your-artifact-repository'
      IMAGE_NAME = 'your-image-name'
      TAG = 'latest'
  }
  stages {
      stage('Authenticate to Google Cloud') {
          steps {
              sh 'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS'
              sh 'gcloud config set project $PROJECT_ID'
          }
      }
      stage('Build Docker Image') {
          steps {
              script {
                  docker.build("${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${IMAGE_NAME}:${TAG}")
              }
          }
      }
      stage('Push Docker Image') {
          steps {
              script {
                  docker.withRegistry("https://${REGION}-docker.pkg.dev", 'gcloud') {
                      docker.image("${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${IMAGE_NAME}:${TAG}").push()
                  }
              }
          }
      }
  }
}</code></pre>
  <p>This setup should get you started with pushing Docker images to Google Artifact Registry directly from Jenkins.
    Let me know if you’d like to dive into more details on any of these steps!</p>
</div>

<a href="/" class="btn btn-secondary mt-3">Back to Home</a>
</div>
</body>

</html>